##开发实录
###IDEA下开发storm-kafka
####maven
在linux下通过maven官网，下载最新的maven，并通过`/etc/profile`配置maven路径。在命令行中输入`mvn --version` 输出下面的内容时，证明maven已经安装
```
mvn --version
Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)
Maven home: /usr/share/apache-maven-3.3.9
Java version: 1.8.0_65, vendor: Oracle Corporation
Java home: /usr/share/jdk1.8.0_65/jre
Default locale: zh_CN, platform encoding: UTF-8
OS name: "linux", version: "3.16.0-70-generic", arch: "amd64", family: "unix"
```
接下来，只需要在IDEA中，通过`setting->Build,Execution,Deployment->Build Tools->Maven`设置Maven home为你刚才解压的Maven目录即可。
####pom.xml
新建Maven项目，在pom.xml中设置库的依赖即可开发storm-kafka，如下所示：

```
 <dependencies>
        <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-core</artifactId>
            <version>0.9.1-incubating</version>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka_2.10</artifactId>
            <version>0.8.1.1</version>
            <exclusions>
                <exclusion>
                    <groupId>org.apache.zookeeper</groupId>
                    <artifactId>zookeeper</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>log4j</groupId>
                    <artifactId>log4j</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
 </dependencies>
```
现在开始storm开发之旅.
在开始开发之前，先让我们看一看kafka是什么。以及我们怎么用kafka的java接口去实现IDE下kafka编程。
###kafka是什么
举个例子，生产者消费者，生产者生产鸡蛋，消费者消费鸡蛋，生产者生产一个鸡蛋，消费者就消费一个鸡蛋，假设消费者消费鸡蛋的时候噎住了（系统宕机了），生产者还在生产鸡蛋，那新生产的鸡蛋就丢失了。再比如生产者很强劲（大交易量的情况），生产者1秒钟生产100个鸡蛋，消费者1秒钟只能吃50个鸡蛋，那要不了一会，消费者就吃不消了（消息堵塞，最终导致系统超时），消费者拒绝再吃了，”鸡蛋“丢失了，这个时候我们放个篮子在它们中间，生产出来的 鸡蛋都放到篮子里，消费者去篮子里拿鸡蛋，这样鸡蛋就不会丢失了，都在篮子里，而这个篮子就是`kafka`。
鸡蛋其实就是“数据流”，系统之间的交互都是通过“数据流”来传输的，也称为报文，也叫“消息”。
消息队列满了，其实就是篮子满了，”鸡蛋“ 放不下了，那赶紧多放几个篮子，其实就是kafka的扩容。
各位现在知道kafka是干什么的了吧，它就是那个"篮子"。 
后面大家会看到一些名词，比如`topic`、`producer`、`consumer`、`broker`，我这边来简单说明一下。

> `producer`：生产者，就是它来生产“鸡蛋”的。 
> `consumer`：消费者，生出的“鸡蛋”它来消费。
> `topic`：你把它理解为标签，生产者每生产出来一个鸡蛋就贴上一个标签（topic），消费者可不是谁生产的“鸡蛋”都吃的，这样不同的生产者生产出来的“鸡蛋”，消费者就可以选择性的“吃”了。
> `broker`：就是篮子了。

下面我们看一下kakfa的消息层次与流程。
####kafka的消息分几个层次：
1. Topic：一类消息，例如page view日志，click日志等都可以以topic的形式存在，kafka集群能够同时负责多个topic的分发
2.  Partition： Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。
3.  Message：消息，最小订阅单元

####具体流程：
1. Producer根据指定的partition方法（round-robin、hash等），将消息发布到指定topic的partition里面
2. kafka集群接收到Producer发过来的消息后，将其持久化到硬盘，并保留消息指定时长（可配置），而不关注消息是否被消费。
3. Consumer从kafka集群pull数据，并控制获取消息的offset

####具体的例子：
未完待续


